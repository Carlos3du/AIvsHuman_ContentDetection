{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c430019",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6b770f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0fba59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04bcf1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1367 entries, 0 to 1366\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   text_content          1367 non-null   object \n",
      " 1   content_type          1367 non-null   object \n",
      " 2   word_count            1367 non-null   int64  \n",
      " 3   character_count       1367 non-null   int64  \n",
      " 4   sentence_count        1367 non-null   int64  \n",
      " 5   lexical_diversity     1367 non-null   float64\n",
      " 6   avg_sentence_length   1367 non-null   float64\n",
      " 7   avg_word_length       1367 non-null   float64\n",
      " 8   punctuation_ratio     1367 non-null   float64\n",
      " 9   flesch_reading_ease   1288 non-null   float64\n",
      " 10  gunning_fog_index     1332 non-null   float64\n",
      " 11  grammar_errors        1367 non-null   int64  \n",
      " 12  passive_voice_ratio   1336 non-null   float64\n",
      " 13  predictability_score  1367 non-null   float64\n",
      " 14  burstiness            1367 non-null   float64\n",
      " 15  sentiment_score       1313 non-null   float64\n",
      " 16  label                 1367 non-null   int64  \n",
      "dtypes: float64(10), int64(5), object(2)\n",
      "memory usage: 181.7+ KB\n"
     ]
    }
   ],
   "source": [
    "raw = pd.read_csv('../data/raw/ia_human_texts.csv')\n",
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13575d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1179 entries, 0 to 1366\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   text_content          1179 non-null   object \n",
      " 1   content_type          1179 non-null   object \n",
      " 2   word_count            1179 non-null   int64  \n",
      " 3   character_count       1179 non-null   int64  \n",
      " 4   sentence_count        1179 non-null   int64  \n",
      " 5   lexical_diversity     1179 non-null   float64\n",
      " 6   avg_sentence_length   1179 non-null   float64\n",
      " 7   avg_word_length       1179 non-null   float64\n",
      " 8   punctuation_ratio     1179 non-null   float64\n",
      " 9   flesch_reading_ease   1179 non-null   float64\n",
      " 10  gunning_fog_index     1179 non-null   float64\n",
      " 11  grammar_errors        1179 non-null   int64  \n",
      " 12  passive_voice_ratio   1179 non-null   float64\n",
      " 13  predictability_score  1179 non-null   float64\n",
      " 14  burstiness            1179 non-null   float64\n",
      " 15  sentiment_score       1179 non-null   float64\n",
      " 16  label                 1179 non-null   int64  \n",
      "dtypes: float64(10), int64(5), object(2)\n",
      "memory usage: 165.8+ KB\n"
     ]
    }
   ],
   "source": [
    "interim = raw.dropna()\n",
    "interim.to_csv('../data/interim/ia_human_texts_int.csv', index=False)\n",
    "interim.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e26dbdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_content</th>\n",
       "      <th>content_type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>passive_voice_ratio</th>\n",
       "      <th>predictability_score</th>\n",
       "      <th>burstiness</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Score each cause. Quality throughout beautiful...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>288</td>\n",
       "      <td>1927</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>53.08</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>105.86</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Board its rock. Job worker break tonight coupl...</td>\n",
       "      <td>essay</td>\n",
       "      <td>253</td>\n",
       "      <td>1719</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.32</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>100.29</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Way debate decision produce. Dream necessary c...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>420</td>\n",
       "      <td>2849</td>\n",
       "      <td>75</td>\n",
       "      <td>0.9071</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.79</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>46.86</td>\n",
       "      <td>7.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>96.88</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>-0.2369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spend value return couple. Marriage method mat...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>198</td>\n",
       "      <td>1383</td>\n",
       "      <td>37</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>5.35</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>43.31</td>\n",
       "      <td>6.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>36.96</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>-0.2755</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Land region back nor article natural measure. ...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>84</td>\n",
       "      <td>551</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>61.16</td>\n",
       "      <td>6.53</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0988</td>\n",
       "      <td>53.49</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        text_content    content_type  \\\n",
       "0  Score each cause. Quality throughout beautiful...  academic_paper   \n",
       "1  Board its rock. Job worker break tonight coupl...           essay   \n",
       "2  Way debate decision produce. Dream necessary c...  academic_paper   \n",
       "5  Spend value return couple. Marriage method mat...       blog_post   \n",
       "6  Land region back nor article natural measure. ...       blog_post   \n",
       "\n",
       "   word_count  character_count  sentence_count  lexical_diversity  \\\n",
       "0         288             1927              54             0.9514   \n",
       "1         253             1719              45             0.9723   \n",
       "2         420             2849              75             0.9071   \n",
       "5         198             1383              37             0.9596   \n",
       "6          84              551              15             0.9762   \n",
       "\n",
       "   avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
       "0                 5.33             5.69             0.0280   \n",
       "1                 5.62             5.80             0.0262   \n",
       "2                 5.60             5.79             0.0263   \n",
       "5                 5.35             5.99             0.0268   \n",
       "6                 5.60             5.57             0.0272   \n",
       "\n",
       "   flesch_reading_ease  gunning_fog_index  grammar_errors  \\\n",
       "0                53.08               7.41               1   \n",
       "1                50.32               8.10               6   \n",
       "2                46.86               7.86               5   \n",
       "5                43.31               6.99               0   \n",
       "6                61.16               6.53               2   \n",
       "\n",
       "   passive_voice_ratio  predictability_score  burstiness  sentiment_score  \\\n",
       "0               0.1041                105.86      0.5531           0.2034   \n",
       "1               0.2045                100.29      0.5643           0.4854   \n",
       "2               0.2308                 96.88      0.4979          -0.2369   \n",
       "5               0.0871                 36.96      0.2328          -0.2755   \n",
       "6               0.0988                 53.49      0.5580           0.9505   \n",
       "\n",
       "   label  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "5      1  \n",
       "6      1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1bd412",
   "metadata": {},
   "source": [
    "## Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7aa05dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carli\\AppData\\Local\\Temp\\ipykernel_20488\\4155568168.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  interim.loc[:, 'content_type_cd'] = le.fit_transform(interim['content_type'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'academic_paper': np.int64(0),\n",
       " 'article': np.int64(1),\n",
       " 'blog_post': np.int64(2),\n",
       " 'creative_writing': np.int64(3),\n",
       " 'essay': np.int64(4),\n",
       " 'news_article': np.int64(5),\n",
       " 'product_review': np.int64(6),\n",
       " 'social_media': np.int64(7)}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "interim.loc[:, 'content_type_cd'] = le.fit_transform(interim['content_type'])\n",
    "content_type_codes = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "content_type_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9bc611",
   "metadata": {},
   "source": [
    "## Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74333fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>passive_voice_ratio</th>\n",
       "      <th>predictability_score</th>\n",
       "      <th>burstiness</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>label</th>\n",
       "      <th>content_type_cd</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.648035</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.6112</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.165385</td>\n",
       "      <td>0.692437</td>\n",
       "      <td>0.232846</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2705</td>\n",
       "      <td>0.859159</td>\n",
       "      <td>0.647810</td>\n",
       "      <td>0.602797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Score each cause. Quality throughout beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.568182</td>\n",
       "      <td>0.577575</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.415704</td>\n",
       "      <td>0.130769</td>\n",
       "      <td>0.673898</td>\n",
       "      <td>0.258718</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.803403</td>\n",
       "      <td>0.663891</td>\n",
       "      <td>0.744136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>Board its rock. Job worker break tonight coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.947727</td>\n",
       "      <td>0.960366</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.413395</td>\n",
       "      <td>0.132692</td>\n",
       "      <td>0.650658</td>\n",
       "      <td>0.249719</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.769269</td>\n",
       "      <td>0.568557</td>\n",
       "      <td>0.382117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Way debate decision produce. Dream necessary c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.443182</td>\n",
       "      <td>0.463753</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.459584</td>\n",
       "      <td>0.142308</td>\n",
       "      <td>0.626814</td>\n",
       "      <td>0.217098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1855</td>\n",
       "      <td>0.169469</td>\n",
       "      <td>0.187940</td>\n",
       "      <td>0.362771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Spend value return couple. Marriage method mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.184091</td>\n",
       "      <td>0.181911</td>\n",
       "      <td>0.170732</td>\n",
       "      <td>0.8096</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.362587</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.746709</td>\n",
       "      <td>0.199850</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.334935</td>\n",
       "      <td>0.654846</td>\n",
       "      <td>0.977245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>Land region back nor article natural measure. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  character_count  sentence_count  lexical_diversity  \\\n",
       "0    0.647727         0.648035        0.646341             0.6112   \n",
       "1    0.568182         0.577575        0.536585             0.7784   \n",
       "2    0.947727         0.960366        0.902439             0.2568   \n",
       "5    0.443182         0.463753        0.439024             0.6768   \n",
       "6    0.184091         0.181911        0.170732             0.8096   \n",
       "\n",
       "   avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
       "0                0.466         0.390300           0.165385   \n",
       "1                0.524         0.415704           0.130769   \n",
       "2                0.520         0.413395           0.132692   \n",
       "5                0.470         0.459584           0.142308   \n",
       "6                0.520         0.362587           0.150000   \n",
       "\n",
       "   flesch_reading_ease  gunning_fog_index  grammar_errors  \\\n",
       "0             0.692437           0.232846             0.1   \n",
       "1             0.673898           0.258718             0.6   \n",
       "2             0.650658           0.249719             0.5   \n",
       "5             0.626814           0.217098             0.0   \n",
       "6             0.746709           0.199850             0.2   \n",
       "\n",
       "   passive_voice_ratio  predictability_score  burstiness  sentiment_score  \\\n",
       "0               0.2705              0.859159    0.647810         0.602797   \n",
       "1               0.7725              0.803403    0.663891         0.744136   \n",
       "2               0.9040              0.769269    0.568557         0.382117   \n",
       "5               0.1855              0.169469    0.187940         0.362771   \n",
       "6               0.2440              0.334935    0.654846         0.977245   \n",
       "\n",
       "   label  content_type_cd                                       text_content  \n",
       "0    1.0         0.000000  Score each cause. Quality throughout beautiful...  \n",
       "1    1.0         0.571429  Board its rock. Job worker break tonight coupl...  \n",
       "2    1.0         0.000000  Way debate decision produce. Dream necessary c...  \n",
       "5    1.0         0.285714  Spend value return couple. Marriage method mat...  \n",
       "6    1.0         0.285714  Land region back nor article natural measure. ...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "interim_norm = interim.drop(columns=['text_content', 'content_type'])\n",
    "interim_norm = interim_norm.astype('float64')\n",
    "\n",
    "interim_norm.loc[:, interim_norm.columns] = scaler.fit_transform(interim_norm)\n",
    "interim_norm = pd.concat([interim_norm, interim['text_content']], axis=1)\n",
    "interim_norm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a8e46f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1179 entries, 0 to 1366\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   word_count            1179 non-null   float64\n",
      " 1   character_count       1179 non-null   float64\n",
      " 2   sentence_count        1179 non-null   float64\n",
      " 3   lexical_diversity     1179 non-null   float64\n",
      " 4   avg_sentence_length   1179 non-null   float64\n",
      " 5   avg_word_length       1179 non-null   float64\n",
      " 6   punctuation_ratio     1179 non-null   float64\n",
      " 7   flesch_reading_ease   1179 non-null   float64\n",
      " 8   gunning_fog_index     1179 non-null   float64\n",
      " 9   grammar_errors        1179 non-null   float64\n",
      " 10  passive_voice_ratio   1179 non-null   float64\n",
      " 11  predictability_score  1179 non-null   float64\n",
      " 12  burstiness            1179 non-null   float64\n",
      " 13  sentiment_score       1179 non-null   float64\n",
      " 14  label                 1179 non-null   float64\n",
      " 15  content_type_cd       1179 non-null   float64\n",
      " 16  text_content          1179 non-null   object \n",
      "dtypes: float64(16), object(1)\n",
      "memory usage: 165.8+ KB\n"
     ]
    }
   ],
   "source": [
    "interim_norm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "57ec31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_norm.to_csv('../data/interim/ia_human_texts_int.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
